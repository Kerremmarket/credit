version: "3.9"

services:
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
      args:
        INCLUDE_TF: "true"  # Include TensorFlow for MLP support
    ports:
      - "8000:8000"
    environment:
      - PORT=8000
      - FRONTEND_ORIGIN=http://localhost:5173
      - DEMO_MODE=true
    volumes:
      # Mount data directory for local access
      - ./backend/data:/app/data:ro
      # Mount models and cache for persistence
      - ./backend/models:/app/models
      - ./backend/cache:/app/cache

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        VITE_API_BASE: "http://localhost:8000"
    ports:
      - "5173:80"
    depends_on:
      - backend

